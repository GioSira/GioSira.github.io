<!DOCTYPE html>
<html lang="en">
<head>
    <title>1st Workshop in Biased Data in Conversational Agents</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="webstyle.css" />
    <link rel="stylesheet" href="css/bootstrap.css" />
    <link rel="stylesheet" href="css/bootstrap.rtl.css" />
    <link rel="stylesheet" href="css/bootstrap-grid.css" />
    <link rel="stylesheet" href="css/bootstrap-grid.rtl.css" />
    <link rel="stylesheet" href="css/bootstrap-reboot.css" />
    <link rel="stylesheet" href="css/bootstrap-reboot.rtl.css" />
    <link rel="stylesheet" href="css/bootstrap-utilities.css" />
    <link rel="stylesheet" href="css/bootstrap-utilities.rtl.css" />
</head>
<body>


    <!--nav class="navbar navbar-expand-md fixed-top navbar-dark bg-dark">
        <a class="navbar-brand" href="#">BIAS 2023</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav">
                <li class="nav-item active">
                    <a class="nav-link" href="#">Home <span class="sr-only">(current)</span></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#">Features</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="#">Pricing</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link disabled" href="#">Disabled</a>
                </li>
            </ul>
        </div>
    </nav -->

    <!-- div class="container-fluid" -->
    <div class="bg-image p-5 text-center shadow-1-strong rounded mb-5 text-white"
        style="background-image: url('img/geometric_background.jpeg');">

        <div class="row" id="title">
            <div class="col-lg-3"></div>
            <div class="col-lg-6">
                <h5>1st Workshop on</h5>
                <h1 class="display-3">Biased Data in Conversational Agents</h1>
                <h4>ECML-PKDD | 22 September 2023  | Turin, Italy</h4>
            </div>
            <div class="col-lg-3"></div>
        </div>

    </div>

    <div class="container-fluid">

        <div class="row">

            <div class="col-lg-3"></div>
            <div class="col-lg-6">

                <h4>News! The program is now <a href="#program">available</a>.</h4>

                <br/><br/>

                <p>
                    Conversational Agents (CA) are now widely prevalent, found in various aspects of
                    our daily interactions, including computers (e.g., ChatGPT), smartphones (e.g., Siri),
                    homes, and websites. These systems may be rule based or statistical based
                    machine learning models, and in the latter case, CAs are trained on conversation
                    corpora that are either gathered in real life settings or created
                    using the Wizard-Of-Oz method. When the corpora are gathered from real life sources
                    like online platforms such as Reddit, the large variety of data ensures generalization
                    in the CA responses, but it may introduce implicit or explicit biases related to racial,
                    sexual, political, or gender matters. The presence of such biases in the data poses
                    a challenge to the construction of CAs, as it may amplify the potential risks that
                    biases pose to society. Therefore, it is crucial to ensure that CAs exhibit
                    responsible and safe behavior in their interactions with users.
                </p>

                <br/>

                <h4>Workshop Objectives</h4>

                <br/>

                <p>
                    The aim of this workshop is to address the challenges posed by biased data in both
                    Machine Learning and society. We invite researchers to compare different
                    chatbots/corpora on sexual, political, racist, or gender topics; study methods to create
                    or mitigate bias during the construction of datasets; define approaches to assess
                    and/or remove bias present in the corpora; or handle bias at the chatbot level through
                    NLP or Machine Learning techniques.
                </p>
                <p>
                    We also welcome submissions that take a
                    theoretical approach to addressing the issue of bias in CAs, without necessarily
                    involving the creation of a corpus, implementation of an agent, or exploration of
                    Machine Learning techniques.
                </p>

            </div>


            <div class="col-lg-3"></div>

        </div>

    </div>

    <div class="container-fluid bg-light">

        <div class="row">
            <div class="col-lg-3"></div>
            <div class="col-lg-6">
                <h3>
                    Topics of Interest
                </h3>
                <p>
                    The workshop solicits contributions including but not limited to the following topics
                </p>
                <ul>
                    <li>
                        Comparison and Evaluation of Corpora/Conversational Agents on biased data
                    </li>
                    <li>
                        Assessing and mitigating biased data in corpora
                    </li>
                    <li>
                        Personalized NLP and Information Retrieval
                    </li>
                    <li>
                        Sexist, Racist, Political and Gender Dictionary and Ontology
                    </li>
                    <li>
                        NLP and Machine Learning methods to recognize and handle biased data
                    </li>
                    <li>
                        Impact of biased data on Conversational Agents
                    </li>
                    <li>
                        Topic recognition and repair strategies in biased conversations
                    </li>
                    <li>
                        Mental Models for biased data
                    </li>
                    <li>
                        Corpora creation and corpora annotation (automatic methods are accepted)
                    </li>
                </ul>
            </div>
            <div class="col-lg-3"></div>
        </div>

    </div>

    <div class="container-fluid">

        <div class="row">

            <div class="col-lg-3"></div>
            <div class="col-lg-6">
                <h3>Submission Instructions</h3>

                <p>
                    Authors are invited to submit original, previously unpublished research papers.
                    <br/>
                    We encourage the submission of:
                    <ul>
                        <li> <b>extended abstracts:</b> 2 pages,</li>
                        <li> <b>short papers:</b> between 5 to 7 pages, </li>
                        <li> <b>regular papers:</b> between 8 to 14 pages.</li>
                    </ul>
                    The space for references is unlimited. <br/>
                </p>

                <p>
                    Abstracts and papers must be written in English and formatted according to the Springer LNCS guidelines.
                    Author instructions, style files, and the copyright form can be downloaded
                    <a href="http://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines"
                            target="_blank" rel="noopener noreferrer">here</a>.
                    All papers must be converted to PDF prior to electronic submission.
                </p>

                <p>
                    All papers need to be ‘best-effort’ <b>anonymized</b>.
                    We strongly encourage making code and data available anonymously
                    (e.g., in an anonymous GitHub repository via Anonymous GitHub or in a Dropbox folder).
                    The authors may have a (non-anonymous) pre-print published online, but it should
                    not be cited in the submitted paper to preserve anonymity.
                    Reviewers will be asked not to search for them.
                </p>

                <p>
                    At least one author of each accepted paper must have a <b>full registration</b> and be <b>in-presence</b>
                    to present the paper. Papers without a full registration or in-presence presentation
                    <b>won't</b> be included in the post-workshop Springer proceedings.
                </p>

                <a href="https://cmt3.research.microsoft.com/ECMLPKDDworkshop2023" target="_blank" rel="noopener noreferrer">
                    <button type="button" class="btn btn-dark">Submit Now</button>
                </a>

                <p>Select: Biased Data in Conversational Agents</p>

            </div>
            <div class="col-lg-3"></div>

        </div>

    </div>

    <div class="container-fluid bg-light">

        <div class="row">

            <div class="col-lg-3"></div>
            <div class="col-lg-6">

                <h3>Important Dates</h3>
                <ul>
                    <li>
                        <b>Paper Submission Deadline:</b> extended to 23 June 2023
                    </li>
                    <li>
                        <b>Paper Author Notification:</b> 12 July 2023
                    </li>
                    <li>
                        <b>Paper Camera Ready:</b> <em>1 October 2023</em>
                    </li>
                </ul>

            </div>
            <div class="col-lg-3"></div>

        </div>

    </div>

    <div class="container-fluid">

        <div class="row">

            <div class="col-lg-3"></div>
            <div class="col-lg-6">

                <h3>Keynote Speaker:</h3>

                <br/>

                <div class="row">

                    <div class="col-lg-4" style="margin-bottom: 5%;">
                        <img alt="Fabio Fossa" src="img/Fabio.jpg" style="margin-bottom: 5%; object-fit: cover;">
                        <h4>Fabio Fossa</h4>
                        <h6>Politecnico of Milan, Italy</h6>
                        <a href="mailto:fabio.fossa@polimi.it">fabio.fossa@polimi.it</a>
                    </div>
                    <div class="col-lg-1"></div>
                    <div class="col-lg-7">
                        <p><b>Gender Bias and Conversational Agents: an Ethical Perspective</b></p>
                        <p style="text-indent: 1.5em;"> In my talk, I intend to discuss ethical problems raised by the
                            implementation of gender-related biases in the design of Embodied Conversational
                            Agents (ECAs). Mainly, I argue that considerable moral risks are attached to this design
                            practice, so that great caution is advised.
                        As artificial conversational agents are increasingly adopted and their linguistic skills perfected,
                            it is important to critically assess related design choices from an ethical point of view as well.
                            In particular, it is pivotal to shed light on the ethical risks of deliberately exploiting
                            pre-existing social biases in order to build technologies that successfully meet user
                            expectations, engender trust, and blend in with their context of use. Accordingly,
                            I address the question whether it is ethical permissible to align the design of ECAs
                            to gender biases in order to improve interactions and maximize user satisfaction.
                        After some introductory considerations on the rationale underlying the design strategy of
                            <i>bias alignment</i>, possible
                            answers to doubts on its ethical permissibility are investigated and their respective
                            contributions to the effort of aligning ECA technology to relevant ethical standards
                            is evaluated. Finally, some conclusive remarks are drawn in terms of design ethics
                            and possible policy recommendations.
                        </p>

                        <p><b>Bio:</b> Fabio Fossa is assistant professor (RTDA) in moral philosophy at the Department
                            of Mechanical Engineering of Politecnico di Milano, Italy. His main research areas are
                            philosophy of technology, robot and AI ethics, applied ethics, and the philosophy of
                            Hans Jonas. His current research deals with the philosophy of artificial agency and
                            the ethics of social robotics and driving automation. He is Editor-In-Chief of the
                            Italian Journal <i>InCircolo – Rivista di filosofia e culture</i> and a member of <i>M</i>ET<i>A –
                            Social Sciences and Humanities for Science and Technology</i>. Among his publications:
                            <i>Ethics of Driving Automation. Artificial Agency and Human Values</i>, Springer 2023.
                        </p>

                    </div>
                </div>

        </div>

    </div>

    <div class="container-fluid bg-light">

        <div class="row">
            <div class="col-lg-3"></div>
            <div class="col-lg-6">

                <h3>Organizing Committee</h3>

                <div class="row">

                    <div class="col-lg-1"></div>

                    <div class="col-lg-3">

                        <div class="card">
                            <img alt="Francesca Grasso" class="card-img-top" src="img/francesca.jpeg">
                            <div class="card-body">
                                <h4 class="card-title">Francesca Grasso</h4>
                                <p class="card-text">University of Turin, Italy</p>
                                <p class="card-text"><a href="mailto:fr.grasso@unito.it">fr.grasso@unito.it</a></p>
                            </div>
                        </div>

                    </div>

                    <div class="col-lg-2"></div>

                    <div class="col-lg-3">

                        <div class="card">
                            <img alt="Giovanni Siragusa" class="card-img-top" src="img/giovanni.jpeg">
                            <div class="card-body">
                                <h4 class="card-title">Giovanni Siragusa</h4>
                                <p class="card-text">University of Turin, Italy</p>
                                <p class="card-text"><a href="mailto:siragusa@di.unito.it">siragusa@di.unito.it</a></p>
                            </div>
                        </div>

                    </div>

                    <div class="col-lg-1"></div>

                </div>

            </div>
            <div class="col-lg-3"></div>
        </div>

    </div>

    <div class="container-fluid">

        <div class="row">

            <div class="col-lg-3"></div>
            <div class="col-lg-6">
                <h3>Program Committee Members</h3>
                <ul id="pc">
                    <li>
                        <b>Kolawole Adebayo</b> - Adapt Center, Ireland
                    </li>
                     <li>
                        <b>Federica Cena</b> - University of Turin, Italy
                    </li>
                    <li>
                        <b>Luigi Di Caro</b> - University of Turin, Italy
                    </li>
                    <li>
                        <b>Shohreh Haddadan</b> - Zortify, Luxembourg
                    </li>
                    <li>
                        <b>Justin Edwards</b> - University of Oulu, Finland
                    </li>
                    <li>
                        <b>Michael Fell</b> - Zortify, Luxembourg
                    </li>
                    <li>
                        <b>Davide Liga</b> - University of Luxembourg, Luxembourg
                    </li>
                    <li>
                        <b>Alessandro Mazzei</b> - University of Turin, Italy
                    </li>
                    <li>
                        <b>Emmanuel Papadakis</b> - University of Huddersfield, United Kingdom
                    </li>
                    <li>
                        <b>Livio Robaldo</b> - Swansea University, Wales
                    </li>
                    <li>
                        <b>Marco Viviani</b> - University of Milan - Bicocca, Italy
                    </li>
                </ul>
                <br/>
            </div>
            <div class="col-lg-3"></div>

        </div>

    </div>

    <div class="container-fluid bg-light">
        <div class="row">
            <div class="col-lg-3"></div>
            <div class="col-lg-6">
                <h3><a name="program">Program</a></h3>
                <h5><b>Location:</b></h5>
                <p>
                    <a href="https://www.polito.it/en/polito/about-us/campuses-and-maps?sellocale=bl_id%253DTO_CIT08%2526fl_id%253DXS01%2526rm_id%253D002&lang=en">
                        Room 1i - Main Campus - Politecnico of Turin (via Castelfidardo 39, Turin)
                    </a>
                </p>
                <br/>
                <h5><b>Schedule:</b></h5>
                <br/>
                <table class="table table-striped">
                    <tbody>
                        <tr>
                            <td>16:30 - 16:35</td>
                            <td>Opening</td>
                        </tr>
                        <tr>
                            <td>16:35 - 17:20</td>
                            <td>
                                <p>
                                    <b>Keynote Speech:</b> Fabio Fossa (Politecnico of Milan)<br/>
                                    <b>Title:</b> Gender Bias and Conversational Agents: an Ethical Perspective
                                </p>
                            </td>
                        </tr>
                        <tr>
                            <td>17:20 - 17:35</td>
                            <td>
                                <p>
                                    <b>How Prevalent is Gender Bias in ChatGPT? - Exploring German and English ChatGPT Responses</b><br/>
                                    Stefanie Urchs, Veronika Thurner, Matthias Aßenmacher, Christian Heumann, and Stephanie Thiemichen
                                </p>
                            </td>
                        </tr>
                        <tr>
                            <td>17:35 - 17:50</td>
                            <td>
                                <p>
                                    <b>Stars, Stripes, and Silicon: Unravelling the ChatGPT’s All-American, Monochrome, Cis-centric Bias</b><br/>
                                    Federico Torrielli
                                </p>
                            </td>
                        </tr>
                        <tr>
                            <td>17:50</td>
                            <td>Closing</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="col-lg-3"></div>
        </div>
    </div>

    <script src="js/bootstrap.js" ></script>
    <script src="js/bootstrap.esm.js"></script>
    <script src="js/bootstrap.bundle.js"></script>

</body>
</html>
